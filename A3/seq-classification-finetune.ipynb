{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install -q bitsandbytes datasets accelerate loralib\n","# !pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n","# !pip install evaluate scikit-learn"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:05.031296Z","iopub.status.busy":"2024-11-03T19:53:05.031003Z","iopub.status.idle":"2024-11-03T19:53:13.022344Z","shell.execute_reply":"2024-11-03T19:53:13.021505Z","shell.execute_reply.started":"2024-11-03T19:53:05.031263Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer, \n","    AutoModelForSequenceClassification,\n","    BitsAndBytesConfig,\n","    Trainer,\n","    TrainingArguments\n",")\n","\n","from datasets import load_dataset\n","from tqdm.autonotebook import tqdm\n","import torch\n","import numpy as np\n","import pandas as pd\n","import os\n","import evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:13.024128Z","iopub.status.busy":"2024-11-03T19:53:13.023508Z","iopub.status.idle":"2024-11-03T19:53:13.028688Z","shell.execute_reply":"2024-11-03T19:53:13.027641Z","shell.execute_reply.started":"2024-11-03T19:53:13.024092Z"},"trusted":true},"outputs":[],"source":["os.environ['WANDB_DISABLED'] = 'true'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:13.030279Z","iopub.status.busy":"2024-11-03T19:53:13.029970Z","iopub.status.idle":"2024-11-03T19:53:13.041513Z","shell.execute_reply":"2024-11-03T19:53:13.040766Z","shell.execute_reply.started":"2024-11-03T19:53:13.030245Z"},"trusted":true},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","\t\tload_in_4bit=True,\n","\t\tbnb_4bit_quant_type='nf4',\n","\t\tbnb_4bit_compute_dtype=torch.float16,\n","\t\tbnb_4bit_use_double_quant=False,\n","\t)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:13.044287Z","iopub.status.busy":"2024-11-03T19:53:13.043975Z","iopub.status.idle":"2024-11-03T19:53:16.494795Z","shell.execute_reply":"2024-11-03T19:53:16.493976Z","shell.execute_reply.started":"2024-11-03T19:53:13.044246Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8750aa578d324e43826efa9d164fc304","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of PhiForSequenceClassification were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_name='microsoft/phi-2'\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map={\"\":0},\n","    trust_remote_code=True,\n","    num_labels=3,\n","    low_cpu_mem_usage=True\n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:16.496149Z","iopub.status.busy":"2024-11-03T19:53:16.495869Z","iopub.status.idle":"2024-11-03T19:53:16.503154Z","shell.execute_reply":"2024-11-03T19:53:16.502321Z","shell.execute_reply.started":"2024-11-03T19:53:16.496118Z"},"trusted":true},"outputs":[],"source":["# inference\n","def predict(text):\n","\tinputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n","\twith torch.no_grad():\n","\t\tlogits = model(**inputs).logits\n","\treturn torch.argmax(logits, dim=-1).item()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:16.504480Z","iopub.status.busy":"2024-11-03T19:53:16.504173Z","iopub.status.idle":"2024-11-03T19:53:16.514457Z","shell.execute_reply":"2024-11-03T19:53:16.513668Z","shell.execute_reply.started":"2024-11-03T19:53:16.504446Z"},"trusted":true},"outputs":[],"source":["for name, param in model.named_parameters():\n","    if 'lora' not in name:\n","        param.requires_grad = False"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:53:16.516580Z","iopub.status.busy":"2024-11-03T19:53:16.515667Z","iopub.status.idle":"2024-11-03T19:53:19.146601Z","shell.execute_reply":"2024-11-03T19:53:19.145744Z","shell.execute_reply.started":"2024-11-03T19:53:16.516530Z"},"trusted":true},"outputs":[],"source":["def select_samples(dataset, step):\n","    dataset = dataset.select(range(0, len(dataset), step))\n","    return dataset\n","\n","dataset = load_dataset('stanfordnlp/snli')\n","dataset['train'] = select_samples(dataset['train'], 550)\n","dataset['validation'] = select_samples(dataset['validation'], 100)\n","dataset['test'] = select_samples(dataset['test'], 100)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:54:50.537962Z","iopub.status.busy":"2024-11-03T19:54:50.537537Z","iopub.status.idle":"2024-11-03T19:54:50.545649Z","shell.execute_reply":"2024-11-03T19:54:50.544452Z","shell.execute_reply.started":"2024-11-03T19:54:50.537922Z"},"trusted":true},"outputs":[],"source":["def preprocess_dataset(dataset):\n","\n","    for split in dataset.keys():\n","\n","        dataset[split] = dataset[split].rename_column('label', 'labels')\n","        dataset[split] = dataset[split].filter(lambda example: example['labels'] != -1)\n","\n","        dataset[split] = dataset[split].map(\n","            lambda example: tokenizer(example['premise'], example['hypothesis'], padding='max_length', truncation=True, max_length=128),\n","            remove_columns=['premise', 'hypothesis']\n","        )\n","    return dataset\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:54:56.437250Z","iopub.status.busy":"2024-11-03T19:54:56.436350Z","iopub.status.idle":"2024-11-03T19:54:57.206522Z","shell.execute_reply":"2024-11-03T19:54:57.205512Z","shell.execute_reply.started":"2024-11-03T19:54:56.437208Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83f45019d0c94a499da521aecd3eb6f9","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee027d5202f34359aaee3bb6ff2d9282","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90fc4b04d1c64451836da57e107637ee","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e69dde114cc847d9b3ff5702a932c155","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/99 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb79082dcf564da583aee6f7bd5749f1","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/1001 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8cf5a19189044308835ec5fae5a577b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = preprocess_dataset(dataset)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:54:57.209374Z","iopub.status.busy":"2024-11-03T19:54:57.208700Z","iopub.status.idle":"2024-11-03T19:54:57.217905Z","shell.execute_reply":"2024-11-03T19:54:57.216795Z","shell.execute_reply.started":"2024-11-03T19:54:57.209326Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PhiForSequenceClassification(\n","  (model): PhiModel(\n","    (embed_tokens): Embedding(51200, 2560)\n","    (embed_dropout): Dropout(p=0.0, inplace=False)\n","    (layers): ModuleList(\n","      (0-31): 32 x PhiDecoderLayer(\n","        (self_attn): PhiSdpaAttention(\n","          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","          (rotary_emb): PhiRotaryEmbedding()\n","        )\n","        (mlp): PhiMLP(\n","          (activation_fn): NewGELUActivation()\n","          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n","          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n","        )\n","        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","        (resid_dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","    (rotary_emb): PhiRotaryEmbedding()\n","  )\n","  (score): Linear(in_features=2560, out_features=3, bias=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:54:57.219506Z","iopub.status.busy":"2024-11-03T19:54:57.219125Z","iopub.status.idle":"2024-11-03T19:54:57.668009Z","shell.execute_reply":"2024-11-03T19:54:57.667115Z","shell.execute_reply.started":"2024-11-03T19:54:57.219462Z"},"trusted":true},"outputs":[],"source":["from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","\n","config = LoraConfig(\n","    r=16, #Rank\n","    lora_alpha=64,\n","    bias=\"none\",\n","    lora_dropout=0.05,\n","    task_type=\"SEQ_CLS\",\n",")\n","\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)\n","\n","peft_model = get_peft_model(model, config)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:54:57.788726Z","iopub.status.busy":"2024-11-03T19:54:57.788297Z","iopub.status.idle":"2024-11-03T19:54:57.808846Z","shell.execute_reply":"2024-11-03T19:54:57.807884Z","shell.execute_reply.started":"2024-11-03T19:54:57.788687Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PeftModelForSequenceClassification(\n","  (base_model): LoraModel(\n","    (model): PhiForSequenceClassification(\n","      (model): PhiModel(\n","        (embed_tokens): Embedding(51200, 2560)\n","        (embed_dropout): Dropout(p=0.0, inplace=False)\n","        (layers): ModuleList(\n","          (0-31): 32 x PhiDecoderLayer(\n","            (self_attn): PhiSdpaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","              (rotary_emb): PhiRotaryEmbedding()\n","            )\n","            (mlp): PhiMLP(\n","              (activation_fn): NewGELUActivation()\n","              (fc1): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=10240, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (fc2): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=10240, out_features=2560, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=10240, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","            )\n","            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","        (rotary_emb): PhiRotaryEmbedding()\n","      )\n","      (score): ModulesToSaveWrapper(\n","        (original_module): Linear(in_features=2560, out_features=3, bias=False)\n","        (modules_to_save): ModuleDict(\n","          (default): Linear(in_features=2560, out_features=3, bias=False)\n","        )\n","      )\n","    )\n","  )\n",")\n"]}],"source":["print(peft_model)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:55:06.554575Z","iopub.status.busy":"2024-11-03T19:55:06.553795Z","iopub.status.idle":"2024-11-03T19:55:06.567955Z","shell.execute_reply":"2024-11-03T19:55:06.566928Z","shell.execute_reply.started":"2024-11-03T19:55:06.554537Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 18357760\n","all model parameters: 1408634880\n","percentage of trainable model parameters: 1.30%\n"]}],"source":["def print_number_of_trainable_model_parameters(model):\n","    trainable_model_params = 0\n","    all_model_params = 0\n","    for _, param in model.named_parameters():\n","        all_model_params += param.numel()\n","        if param.requires_grad:\n","            trainable_model_params += param.numel()\n","    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n","\n","print(print_number_of_trainable_model_parameters(peft_model))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:55:07.612906Z","iopub.status.busy":"2024-11-03T19:55:07.612518Z","iopub.status.idle":"2024-11-03T19:55:08.089230Z","shell.execute_reply":"2024-11-03T19:55:08.088341Z","shell.execute_reply.started":"2024-11-03T19:55:07.612871Z"},"trusted":true},"outputs":[],"source":["metric = evaluate.load('accuracy')\n","\n","def compute_metrics(pred):\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:55:08.090985Z","iopub.status.busy":"2024-11-03T19:55:08.090646Z","iopub.status.idle":"2024-11-03T19:55:08.742049Z","shell.execute_reply":"2024-11-03T19:55:08.740918Z","shell.execute_reply.started":"2024-11-03T19:55:08.090952Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1570: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}],"source":["output_dir = './peft-snli/final-checkpoint'\n","import transformers\n","\n","peft_training_args = TrainingArguments(\n","    output_dir = output_dir,\n","    per_device_train_batch_size=64,\n","    per_device_eval_batch_size=2,\n","    num_train_epochs=5,\n","    learning_rate=0.0001,\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    evaluation_strategy=\"epoch\",\n","    overwrite_output_dir=True,\n",")\n","\n","peft_model.config.use_cache = False\n","\n","peft_trainer = transformers.Trainer(\n","    model=peft_model,\n","    train_dataset=dataset['train'],\n","    eval_dataset=dataset['validation'],\n","    args=peft_training_args\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:55:08.744072Z","iopub.status.busy":"2024-11-03T19:55:08.743713Z","iopub.status.idle":"2024-11-03T19:55:08.751301Z","shell.execute_reply":"2024-11-03T19:55:08.750222Z","shell.execute_reply.started":"2024-11-03T19:55:08.744037Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["peft_training_args.device"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:55:09.193965Z","iopub.status.busy":"2024-11-03T19:55:09.193544Z","iopub.status.idle":"2024-11-03T19:55:09.198960Z","shell.execute_reply":"2024-11-03T19:55:09.197909Z","shell.execute_reply.started":"2024-11-03T19:55:09.193925Z"},"trusted":true},"outputs":[],"source":["peft_model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T19:55:10.781173Z","iopub.status.busy":"2024-11-03T19:55:10.780536Z","iopub.status.idle":"2024-11-03T20:26:29.958924Z","shell.execute_reply":"2024-11-03T20:26:29.957731Z","shell.execute_reply.started":"2024-11-03T19:55:10.781131Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [80/80 30:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.181000</td>\n","      <td>0.941513</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.760900</td>\n","      <td>0.684881</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.489000</td>\n","      <td>0.563480</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.345700</td>\n","      <td>0.548573</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.255400</td>\n","      <td>0.521142</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"data":{"text/plain":["TrainOutput(global_step=80, training_loss=0.60637948513031, metrics={'train_runtime': 1878.755, 'train_samples_per_second': 2.664, 'train_steps_per_second': 0.043, 'total_flos': 9747417346867200.0, 'train_loss': 0.60637948513031, 'epoch': 5.0})"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["peft_trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["![Example Image](./image.png)\n","\n","### Thus the time taken in 30 min 55 sec"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T20:26:57.141123Z","iopub.status.busy":"2024-11-03T20:26:57.140201Z","iopub.status.idle":"2024-11-03T20:27:54.401476Z","shell.execute_reply":"2024-11-03T20:27:54.400277Z","shell.execute_reply.started":"2024-11-03T20:26:57.141082Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/peft-snli/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/optimizer.pt (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/README.md (deflated 66%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/adapter_config.json (deflated 53%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/adapter_model.safetensors (deflated 7%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/trainer_state.json (deflated 63%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-32/training_args.bin (deflated 51%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/optimizer.pt (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/README.md (deflated 66%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/adapter_config.json (deflated 53%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/adapter_model.safetensors (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/trainer_state.json (deflated 70%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-64/training_args.bin (deflated 51%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/optimizer.pt (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/README.md (deflated 66%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/adapter_config.json (deflated 53%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/adapter_model.safetensors (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/trainer_state.json (deflated 67%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-48/training_args.bin (deflated 51%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/optimizer.pt (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/README.md (deflated 66%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/adapter_config.json (deflated 53%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/adapter_model.safetensors (deflated 8%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/trainer_state.json (deflated 72%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-80/training_args.bin (deflated 51%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/optimizer.pt (deflated 9%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/README.md (deflated 66%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/adapter_config.json (deflated 53%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/adapter_model.safetensors (deflated 7%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/trainer_state.json (deflated 58%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/checkpoint-16/training_args.bin (deflated 51%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-55-08_ce94f9d49346/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-55-08_ce94f9d49346/events.out.tfevents.1730663711.ce94f9d49346.316.0 (deflated 61%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-43-12_ce94f9d49346/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-43-12_ce94f9d49346/events.out.tfevents.1730662993.ce94f9d49346.194.0 (deflated 63%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-41-53_ce94f9d49346/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-41-53_ce94f9d49346/events.out.tfevents.1730662914.ce94f9d49346.30.0 (deflated 63%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-44-15_ce94f9d49346/ (stored 0%)\n","  adding: kaggle/working/peft-snli/final-checkpoint/runs/Nov03_19-44-15_ce94f9d49346/events.out.tfevents.1730663056.ce94f9d49346.253.0 (deflated 61%)\n"]}],"source":["!zip -r model.zip '/kaggle/working/peft-snli'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
